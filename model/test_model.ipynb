{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import load_model\n",
    "import keras.backend as K\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.layers import Input, Dense, Conv1D, Flatten, MaxPooling1D, Conv2D, MaxPooling2D, AveragePooling2D, Dropout, Reshape, normalization\n",
    "from keras.models import Model\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers.recurrent import LSTM\n",
    "from sklearn import metrics\n",
    "import random\n",
    "from keras.models import model_from_json\n",
    "\n",
    "#define evaluation indicators\n",
    "def precision(y_true, y_pred):\n",
    "    # Calculates the precision\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    # Calculates the recall\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def f1(test_Y, pre_test_y):\n",
    "     #calculate the F1-score\n",
    "    Precision = precision(test_Y, pre_test_y)\n",
    "    Recall = recall(test_Y, pre_test_y)\n",
    "    f1 = 2 * ((Precision * Recall) / (Precision + Recall + K.epsilon()))\n",
    "    return f1 \n",
    "\n",
    "def TP(test_Y,pre_test_y):\n",
    "    #calculate numbers of true positive samples\n",
    "    TP = K.sum(K.round(K.clip(test_Y * pre_test_y, 0, 1)))#TP\n",
    "    return TP\n",
    "\n",
    "def FN(test_Y,pre_test_y):\n",
    "     #calculate numbers of false negative samples\n",
    "    TP = K.sum(K.round(K.clip(test_Y * pre_test_y, 0, 1)))#TP\n",
    "    P=K.sum(K.round(K.clip(test_Y, 0, 1)))\n",
    "    FN = P-TP #FN=P-TP\n",
    "    return FN\n",
    "\n",
    "def TN(test_Y,pre_test_y):\n",
    "    #calculate numbers of True negative samples\n",
    "    TN=K.sum(K.round(K.clip((test_Y-K.ones_like(test_Y))*(pre_test_y-K.ones_like(pre_test_y)), 0, 1)))#TN\n",
    "    return TN\n",
    "\n",
    "def FP(test_Y,pre_test_y):\n",
    "    #calculate numbers of False positive samples\n",
    "    N = (-1)*K.sum(K.round(K.clip(test_Y-K.ones_like(test_Y), -1, 0)))#N\n",
    "    TN=K.sum(K.round(K.clip((test_Y-K.ones_like(test_Y))*(pre_test_y-K.ones_like(pre_test_y)), 0, 1)))#TN\n",
    "    FP=N-TN\n",
    "    return FP\n",
    "\n",
    "data = np.array(pd.read_csv(\"exampleFeatureFile.csv\")) #testing set\n",
    "    \n",
    "X1 = data[0:1261, 1:] #1261 is the number of positive samples in testing set, '1' is the label of positive sample\n",
    "Y1 = data[0:1261, 0] #'0' is the label of negative sample\n",
    "X2 = data[1261:, 1:]\n",
    "Y2 = data[1261:, 0]\n",
    "X = np.concatenate([X1, X2], 0)\n",
    "Y = np.concatenate([Y1, Y2], 0)\n",
    "#Y = Y.reshape((Y.shape[0], -1))\n",
    "X = np.expand_dims(X, 2)\n",
    "print X\n",
    "print \"X.shape: \", X.shape\n",
    "print \"Y.shape: \", Y.shape\n",
    "\n",
    "model_name = 'example.h5' #load model generated by train_CNN_model.ipynb\n",
    "model_back = load_model(model_name,\n",
    "                        custom_objects={'precision': precision,'recall':recall,'f1':f1,'TP':TP,'FN':FN,'TN':TN,'FP':FP})\n",
    "# model = load_model('pcsf.h5')\n",
    "accuracy = model_back.evaluate(X,Y)\n",
    "# print 'loss', loss\n",
    "print 'accuracy', accuracy \n",
    "maxprobability = model_back.predict(X)\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "print maxprobability #print maxprobability\n",
    "fw = open('showForUserResult.txt','w') #define result outputFile \n",
    "myprob = \"\\n\".join(map(str, maxprobability[:, 0]))\n",
    "fw.write(myprob)\n",
    "predictclass = model_back.predict(X)\n",
    "predictclass = np.argmax(predictclass,axis=1)\n",
    "print predictclass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
