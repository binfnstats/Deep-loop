{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.layers import Input, Dense, Conv1D, Flatten, MaxPooling1D, Conv2D, MaxPooling2D, AveragePooling2D, Dropout, Reshape, normalization\n",
    "from keras.models import Model\n",
    "from keras.utils import to_categorical\n",
    "import keras.backend as K\n",
    "from keras.layers.recurrent import LSTM\n",
    "from sklearn import metrics\n",
    "import random\n",
    "\n",
    "#define evaluation indicators\n",
    "def precision(y_true, y_pred):\n",
    "    # Calculates the precision\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    # Calculates the recall\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def f1(test_Y, pre_test_y):\n",
    "    #calculate the F1-score\n",
    "    Precision = precision(test_Y, pre_test_y)\n",
    "    Recall = recall(test_Y, pre_test_y)\n",
    "    f1 = 2 * ((Precision * Recall) / (Precision + Recall + K.epsilon()))\n",
    "    return f1 \n",
    "\n",
    "def TP(test_Y,pre_test_y):\n",
    "    #calculate numbers of true positive samples\n",
    "    TP = K.sum(K.round(K.clip(test_Y * pre_test_y, 0, 1)))#TP\n",
    "    return TP\n",
    "\n",
    "def FN(test_Y,pre_test_y):\n",
    "    #calculate numbers of false negative samples\n",
    "    TP = K.sum(K.round(K.clip(test_Y * pre_test_y, 0, 1)))#TP\n",
    "    P=K.sum(K.round(K.clip(test_Y, 0, 1)))\n",
    "    FN = P-TP #FN=P-TP\n",
    "    return FN\n",
    "\n",
    "def TN(test_Y,pre_test_y):\n",
    "    #calculate numbers of True negative samples\n",
    "    TN=K.sum(K.round(K.clip((test_Y-K.ones_like(test_Y))*(pre_test_y-K.ones_like(pre_test_y)), 0, 1)))#TN\n",
    "    return TN\n",
    "\n",
    "def FP(test_Y,pre_test_y):\n",
    "    #calculate numbers of False positive samples\n",
    "    N = (-1)*K.sum(K.round(K.clip(test_Y-K.ones_like(test_Y), -1, 0)))#N\n",
    "    TN=K.sum(K.round(K.clip((test_Y-K.ones_like(test_Y))*(pre_test_y-K.ones_like(pre_test_y)), 0, 1)))#TN\n",
    "    FP=N-TN\n",
    "    return FP\n",
    "\n",
    "#train model\n",
    "def dnn_model(train_X, train_Y, test_X, test_Y, lr, epoch, batch_size):\n",
    "    train_X = np.expand_dims(train_X, 2)\n",
    "    test_X = np.expand_dims(test_X, 2)\n",
    "    inputs = Input(shape = (train_X.shape[1], train_X.shape[2]))\n",
    "    x = Conv1D(32, kernel_size = 3, strides = 1, padding = 'valid', activation = 'relu')(inputs)\n",
    "    x = MaxPooling1D(pool_size = 2, strides = 2, padding = 'same')(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dropout(0.5)(x)#regularizer\n",
    "    x = Dense(32, activation = 'relu')(x)\n",
    "    x = Dense(16, activation = 'relu')(x)\n",
    "    x = Dense(8, activation = 'relu')(x)\n",
    "    predictions = Dense(1, activation = 'sigmoid')(x)\n",
    "    model = Model(inputs = inputs, outputs = predictions)\n",
    "    print(\"model\")\n",
    "    model.compile(optimizer = 'RMSprop',\n",
    "                  loss = 'mean_squared_error',\n",
    "                  metrics = ['acc',precision,recall,f1,TP,FN,TN,FP])\n",
    "    print(\"compile\")\n",
    "    model.fit(train_X, train_Y, epochs = epoch, batch_size = 32, validation_data = (test_X, test_Y), shuffle = True)\n",
    "    model.save('example.h5') #save model\n",
    "    pre_test_y = model.predict(test_X, batch_size = 50)\n",
    "    pre_train_y = model.predict(train_X, batch_size = 50)\n",
    "    test_auc = metrics.roc_auc_score(test_Y, pre_test_y)\n",
    "    train_auc = metrics.roc_auc_score(train_Y, pre_train_y)\n",
    "    print(\"train_auc: \", train_auc)\n",
    "    print(\"test_auc: \", test_auc) \n",
    "    return test_auc\n",
    "\n",
    "# split data and output result\n",
    "data = np.array(pd.read_csv(\"exampleFeatureFile.csv\"))#inputfile\n",
    "X1 = data[0:1261, 1:]#1054 is the number of positive samples in training set, '1' is the label of positive sample\n",
    "Y1 = data[0:1261, 0]#'0' is the label of negative sample\n",
    "X2 = data[1261:, 1:]\n",
    "Y2 = data[1261:, 0]\n",
    "X = np.concatenate([X1, X2], 0)\n",
    "Y = np.concatenate([Y1, Y2], 0)\n",
    "#Y = Y.reshape((Y.shape[0], -1))\n",
    "print X\n",
    "print \"X.shape: \", X.shape\n",
    "print \"Y.shape: \", Y.shape\n",
    "\n",
    "lr = 0.2 #learning rate\n",
    "epoch = 20 \n",
    "batch_size = 32\n",
    "kf = KFold(n_splits = 10, shuffle = True, random_state = 42) #set cross-validation\n",
    "#kf = KFold(n_splits = 5, shuffle = False)\n",
    "kf = kf.split(X)\n",
    "\n",
    "test_aucs = []\n",
    "for i, (train_fold, validate_fold) in enumerate(kf):\n",
    "    print(\"\\n\\ni: \", i)\n",
    "    test_auc = dnn_model(X[train_fold], Y[train_fold], X[validate_fold], Y[validate_fold], lr, epoch, batch_size)\n",
    "    test_aucs.append(test_auc)\n",
    "w = open(\"outputResultFile.csv\", \"w\")#final result file\n",
    "for j in test_aucs: \n",
    "    w.write(str(j) + ',')\n",
    "w.write('\\n')\n",
    "w.write(str(np.mean(test_aucs)) + '\\n')\n",
    "w.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
